import {
  AIPrompt,
  AIGenerationOptions,
  AIServiceResponse,
  ScriptData,
} from "../../../types/ai";
import { ApiKeyManager } from "../ApiKeyManager";
import { SecureApiKeyManager } from "../SecureApiKeyManager";
import {
  AI_PROVIDERS,
  DEFAULT_GENERATION_OPTIONS,
  getEnabledProviders,
} from "../../../config/aiConfig";
import { createLogger } from "../../../utils/optimizedLogger";
import { CacheManager } from "../CacheManager";
import { ApiClient } from "../../api/ApiClient";
import { SERVER_CONFIG } from "../../../config/serverConfig";
import AsyncStorage from "@react-native-async-storage/async-storage";
import { ManagedAPIService } from "../../subscription";
import { ProviderRegistry } from "../../subscription/providers/ProviderRegistry";

const logger = createLogger("ScriptGenerationService");

export class ScriptGenerationService {
  /**
   * G√©n√®re un script en utilisant le syst√®me unifi√© d'IA
   */
  static async generateScript(
    prompt: AIPrompt,
    options: AIGenerationOptions = DEFAULT_GENERATION_OPTIONS
  ): Promise<AIServiceResponse> {
    const mergedOptions = { ...DEFAULT_GENERATION_OPTIONS, ...options };

    // V√©rifier le cache
    const cachedResponse = await CacheManager.getCachedResponse(
      prompt,
      mergedOptions
    );
    if (cachedResponse) {
      logger.info("R√©ponse r√©cup√©r√©e depuis le cache", { topic: prompt.topic });
      return cachedResponse;
    }

    // Essayer le serveur proxy d'abord
    if (!SERVER_CONFIG.BYPASS_PROXY) {
      try {
        const proxyResponse = await this.tryProxyGeneration(prompt);
        if (proxyResponse) {
          await CacheManager.cacheResponse(
            prompt,
            mergedOptions,
            proxyResponse,
            "PROXY"
          );
          return proxyResponse;
        }
      } catch (error) {
        logger.error("Erreur proxy, fallback vers API directe", error);
      }
    }

    // Utiliser le syst√®me unifi√© d'IA
    return this.generateWithUnifiedSystem(prompt, mergedOptions);
  }

  /**
   * G√©n√©ration via le serveur proxy
   */
  private static async tryProxyGeneration(
    prompt: AIPrompt
  ): Promise<AIServiceResponse | null> {
    try {
      logger.info("Tentative via serveur proxy");
      return await ApiClient.generateScript({
        topic: prompt.topic,
        platform: prompt.platform,
        tone: prompt.tone,
        duration: prompt.duration || "medium",
        language: prompt.language,
        creativity: prompt.creativity || 0.7,
        characterCount: prompt.characterCount,
      });
    } catch (error) {
      logger.error("√âchec du serveur proxy", error);
      return null;
    }
  }

  /**
   * G√©n√©ration avec le syst√®me unifi√© d'IA
   */
  private static async generateWithUnifiedSystem(
    prompt: AIPrompt,
    options: AIGenerationOptions
  ): Promise<AIServiceResponse> {
    const enabledProviders = await getEnabledProviders();

    if (enabledProviders.length === 0) {
      throw new Error(await this.getNoProvidersErrorMessage());
    }

    // R√©cup√©rer les infos utilisateur pour le syst√®me manag√©
    const { userId, planId } = await this.getUserInfo();

    logger.info(`Providers disponibles: ${enabledProviders.join(", ")}`);

    // Essayer chaque provider
    for (const provider of enabledProviders) {
      try {
        logger.info(`Tentative avec ${provider}`);

        const result = await this.callProvider(
          provider,
          prompt,
          options,
          userId,
          planId
        );
        if (result) {
          await CacheManager.cacheResponse(prompt, options, result, provider);
          return result;
        }
      } catch (error) {
        logger.error(`Erreur avec ${provider}:`, error);
        continue;
      }
    }

    throw new Error(
      "Impossible de se connecter aux services d'IA. V√©rifiez votre connexion et les cl√©s API."
    );
  }

  /**
   * Appel √† un provider sp√©cifique
   */
  private static async callProvider(
    provider: string,
    prompt: AIPrompt,
    options: AIGenerationOptions,
    userId: string,
    planId: string
  ): Promise<AIServiceResponse | null> {
    // Construire le prompt pour la g√©n√©ration de script
    const fullPrompt = this.buildScriptPrompt(prompt, options);

    try {
      // Essayer d'abord le syst√®me manag√©
      if (ManagedAPIService.canUseAPI(provider, planId)) {
        const response = await ManagedAPIService.makeAPICall({
          provider: provider.toLowerCase(),
          prompt: fullPrompt,
          userId,
          planId,
          maxTokens: 1500,
          temperature: prompt.creativity || 0.7,
        });

        if (response.success) {
          const content = this.extractContentFromResponse(
            provider,
            response.data
          );
          if (content) {
            return this.formatScriptResponse(provider, content, prompt);
          }
        }
      }

      // Fallback sur appel direct
      return await this.callProviderDirect(provider, fullPrompt, prompt);
    } catch (error) {
      logger.error(`Erreur lors de l'appel √† ${provider}:`, error);
      return null;
    }
  }

  /**
   * Appel direct √† un provider via le syst√®me centralis√©
   */
  private static async callProviderDirect(
    provider: string,
    fullPrompt: string,
    originalPrompt: AIPrompt
  ): Promise<AIServiceResponse | null> {
    try {
      // Utiliser le syst√®me centralis√© ProviderRegistry
      const providerInstance = ProviderRegistry.getProvider(provider);
      if (!providerInstance) {
        logger.warn(`Provider ${provider} non trouv√© dans le registre`);
        return null;
      }

      const apiKey = await SecureApiKeyManager.getApiKey(
        provider.toLowerCase()
      );
      if (!apiKey) {
        logger.warn(`Cl√© API manquante pour ${provider}`);
        return null;
      }

      // R√©cup√©rer les infos utilisateur
      const { userId, planId } = await this.getUserInfo();

      // Appel unifi√© via le syst√®me centralis√©
      const response = await providerInstance.call(
        apiKey,
        {
          provider: provider.toLowerCase(),
          prompt: fullPrompt,
          maxTokens: 1500,
          temperature: originalPrompt.creativity || 0.7,
          userId,
          planId,
          model: this.getDefaultModel(provider),
        },
        {
          model: this.getDefaultModel(provider),
          maxTokens: 1500,
          temperature: originalPrompt.creativity || 0.7,
        }
      );

      if (response.tokensUsed) {
        logger.info(`Tokens utilis√©s avec ${provider}: ${response.tokensUsed}`);
      }

      // Extraction du contenu via le syst√®me unifi√©
      const content = this.extractContentFromUnifiedResponse(
        provider,
        response.data
      );

      if (content) {
        return this.formatScriptResponse(provider, content, originalPrompt);
      }

      return null;
    } catch (error) {
      logger.error(`Erreur appel direct ${provider}:`, error);
      return null;
    }
  }

  /**
   * Construit le prompt pour la g√©n√©ration de script
   */
  private static buildScriptPrompt(
    prompt: AIPrompt,
    options: AIGenerationOptions
  ): string {
    const systemPrompt = `Tu es un assistant sp√©cialis√© dans la cr√©ation de scripts pour vid√©os et t√©l√©prompter. 
Cr√©e des scripts captivants, structur√©s et adapt√©s √† l'audience cible.

R√®gles importantes:
- R√©ponds dans la langue demand√©e: ${prompt.language || "fran√ßais"}
- Adapte le ton: ${prompt.tone}
- Plateforme cible: ${prompt.platform}
- Dur√©e approximative: ${prompt.duration || "medium"}
${options.includeHooks ? "- Inclure des accroches" : ""}
${options.includeCallToAction ? "- Inclure un appel √† l'action" : ""}
${options.includeHashtags ? "- Inclure des hashtags pertinents" : ""}`;

    return `${systemPrompt}\n\nSujet: ${prompt.topic}\n\nCr√©e un script complet et engageant.`;
  }

  /**
   * Extrait le contenu de la r√©ponse selon le provider
   */
  private static extractContentFromResponse(
    provider: string,
    data: any
  ): string | null {
    try {
      switch (provider.toLowerCase()) {
        case "openai":
        case "mistral":
          return data?.choices?.[0]?.message?.content;
        case "gemini":
          return data?.candidates?.[0]?.content?.parts?.[0]?.text;
        case "cohere":
          return data?.generations?.[0]?.text;
        case "claude":
          return data?.content?.[0]?.text;
        case "perplexity":
        case "together":
        case "groq":
        case "fireworks":
          return data?.choices?.[0]?.message?.content;
        default:
          return null;
      }
    } catch (error) {
      logger.error(`Erreur extraction contenu ${provider}:`, error);
      return null;
    }
  }

  /**
   * Extrait le contenu de la r√©ponse unifi√©e
   */
  private static extractContentFromUnifiedResponse(
    provider: string,
    data: any
  ): string | null {
    // Le syst√®me centralis√© retourne d√©j√† des donn√©es normalis√©es
    // Mais on garde une extraction sp√©cifique pour √™tre s√ªr
    return this.extractContentFromResponse(provider, data);
  }

  /**
   * Formate la r√©ponse en AIServiceResponse
   */
  private static formatScriptResponse(
    provider: string,
    content: string,
    prompt: AIPrompt
  ): AIServiceResponse {
    return {
      id: `${provider.toLowerCase()}_${Date.now()}`,
      title: `Script ${prompt.platform} - ${prompt.topic}`,
      content: content.trim(),
      createdAt: new Date().toISOString(),
      updatedAt: new Date().toISOString(),
      isAIGenerated: true,
      aiPrompt: prompt,
    };
  }

  /**
   * Obtient le mod√®le par d√©faut pour un provider
   */
  private static getDefaultModel(provider: string): string {
    const defaultModels: Record<string, string> = {
      [AI_PROVIDERS.OPENAI]: "gpt-4o-mini",
      [AI_PROVIDERS.GEMINI]: "gemini-2.0-flash",
      [AI_PROVIDERS.MISTRAL]: "mistral-tiny",
      [AI_PROVIDERS.COHERE]: "command",
      [AI_PROVIDERS.CLAUDE]: "claude-3-sonnet-20240229",
      [AI_PROVIDERS.PERPLEXITY]: "llama-3.1-sonar-small-128k-online",
      [AI_PROVIDERS.TOGETHER]: "meta-llama/Llama-2-7b-chat-hf",
      [AI_PROVIDERS.GROQ]: "llama2-70b-4096",
      [AI_PROVIDERS.FIREWORKS]: "accounts/fireworks/models/llama-v2-7b-chat",
    };

    return defaultModels[provider] || "default";
  }

  /**
   * R√©cup√®re les informations utilisateur
   */
  private static async getUserInfo(): Promise<{
    userId: string;
    planId: string;
  }> {
    try {
      const currentUser = await AsyncStorage.getItem("@current_user");
      const subscription = await AsyncStorage.getItem("user_subscription");

      let userId = "anonymous";
      let planId = "free";

      if (currentUser) {
        const userData = JSON.parse(currentUser);
        userId = userData.uid || "anonymous";
      }

      if (subscription) {
        const subscriptionData = JSON.parse(subscription);
        if (subscriptionData.status === "active") {
          planId = subscriptionData.planId || "free";
        }
      }

      return { userId, planId };
    } catch (error) {
      logger.error("Erreur r√©cup√©ration infos utilisateur:", error);
      return { userId: "anonymous", planId: "free" };
    }
  }

  /**
   * Message d'erreur quand aucun provider n'est disponible
   */
  private static async getNoProvidersErrorMessage(): Promise<string> {
    const [
      hasOpenAIKey,
      hasGeminiKey,
      hasMistralKey,
      hasCohereKey,
      hasClaudeKey,
      hasPerplexityKey,
      hasTogetherKey,
      hasGroqKey,
      hasFireworksKey,
    ] = await Promise.all([
      SecureApiKeyManager.hasValidKey("openai"),
      SecureApiKeyManager.hasValidKey("gemini"),
      SecureApiKeyManager.hasValidKey("mistral"),
      SecureApiKeyManager.hasValidKey("cohere"),
      SecureApiKeyManager.hasValidKey("claude"),
      SecureApiKeyManager.hasValidKey("perplexity"),
      SecureApiKeyManager.hasValidKey("together"),
      SecureApiKeyManager.hasValidKey("groq"),
      SecureApiKeyManager.hasValidKey("fireworks"),
    ]);

    const hasAnyKey =
      hasOpenAIKey ||
      hasGeminiKey ||
      hasMistralKey ||
      hasCohereKey ||
      hasClaudeKey ||
      hasPerplexityKey ||
      hasTogetherKey ||
      hasGroqKey ||
      hasFireworksKey;

    if (hasAnyKey) {
      return "üîå Aucun service AI activ√©.\n\nVous avez des cl√©s API configur√©es mais aucun service n'est activ√©.\n\nAllez dans Param√®tres ‚Üí Configuration AI et activez au moins un service.";
    } else {
      return "üîë Aucune cl√© API configur√©e.\n\nPour utiliser la g√©n√©ration AI, vous devez :\n1. Obtenir une cl√© API gratuite (Gemini, Mistral ou Cohere)\n2. Aller dans Param√®tres ‚Üí Configuration AI\n3. Entrer votre cl√© et activer le service";
    }
  }

  /**
   * G√©n√®re plusieurs variantes d'un script
   */
  static async generateVariants(
    basePrompt: AIPrompt,
    count: number = 3
  ): Promise<AIServiceResponse[]> {
    const variants: AIServiceResponse[] = [];

    for (let i = 0; i < count; i++) {
      try {
        const creativity = Math.min(
          1.0,
          Math.max(
            0.1,
            (basePrompt.creativity || 0.7) + (Math.random() * 0.2 - 0.1)
          )
        );

        const variantPrompt: AIPrompt = {
          ...basePrompt,
          creativity,
          ...(i === 1 && { emotionalTone: "positive" }),
          ...(i === 2 && { narrativeStructure: "story-based" }),
        };

        const result = await this.generateScript(variantPrompt);
        variants.push({
          ...result,
          title: `Variante ${i + 1}: ${result.title}`,
        });
      } catch (error) {
        logger.error(`Erreur variante ${i + 1}:`, error);
      }
    }

    if (variants.length === 0) {
      throw new Error(
        "Impossible de g√©n√©rer des variantes. Veuillez r√©essayer."
      );
    }

    return variants;
  }

  /**
   * Sauvegarde un script
   */
  static async saveScript(script: ScriptData): Promise<boolean> {
    try {
      // TODO: Impl√©menter la sauvegarde persistante
      logger.info("Script sauvegard√©", { scriptId: script.id });
      return true;
    } catch (error) {
      logger.error("Erreur sauvegarde script:", error);
      return false;
    }
  }
}
