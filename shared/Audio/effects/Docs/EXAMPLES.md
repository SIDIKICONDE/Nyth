# üìù Exemples d'utilisation - Effets Audio

## Vue d'ensemble

Cette section pr√©sente des exemples pratiques d'utilisation du syst√®me d'effets audio dans diff√©rentes situations courantes.

## üéµ Exemple 1 : Configuration basique d'un compresseur

### Objectif

Cr√©er et configurer un compresseur simple pour contr√¥ler les niveaux audio.

```javascript
import { NativeAudioEffectsModule } from './native-modules';

class BasicCompressor {
  constructor() {
    this.effectsModule = new NativeAudioEffectsModule();
    this.compressorId = null;
    this.isInitialized = false;
  }

  // Initialisation du syst√®me
  async initialize() {
    try {
      const success = await this.effectsModule.initialize();
      if (!success) {
        throw new Error("√âchec de l'initialisation du module");
      }

      // Configuration du compresseur
      this.compressorId = await this.effectsModule.createEffect({
        type: 'compressor',
        parameters: {
          thresholdDb: -10.0, // Seuil √† -10 dB
          ratio: 4.0, // Ratio 4:1
          attackMs: 10.0, // Attack rapide
          releaseMs: 100.0, // Release moyenne
          makeupDb: 0.0, // Pas de makeup gain
        },
        enabled: true,
      });

      if (this.compressorId === -1) {
        throw new Error('√âchec de la cr√©ation du compresseur');
      }

      this.isInitialized = true;
      console.log('Compresseur initialis√© avec succ√®s');
    } catch (error) {
      console.error("Erreur d'initialisation:", error);
      throw error;
    }
  }

  // Traitement audio
  async processAudio(audioBuffer) {
    if (!this.isInitialized) {
      throw new Error('Module non initialis√©');
    }

    try {
      const processedBuffer = await this.effectsModule.processAudio(
        audioBuffer,
        1, // Mono
      );

      return processedBuffer;
    } catch (error) {
      console.error('Erreur de traitement:', error);
      return audioBuffer; // Retour buffer original en cas d'erreur
    }
  }

  // Nettoyage
  async dispose() {
    if (this.compressorId !== null) {
      await this.effectsModule.destroyEffect(this.compressorId);
      this.compressorId = null;
    }

    await this.effectsModule.dispose();
    this.isInitialized = false;
  }
}

// Utilisation
const compressor = new BasicCompressor();
await compressor.initialize();

// Traitement d'un buffer audio
const inputBuffer = [0.1, 0.5, 0.8, 0.3, 0.1];
const outputBuffer = await compressor.processAudio(inputBuffer);

console.log('Buffer trait√©:', outputBuffer);

// Nettoyage
await compressor.dispose();
```

## üéõÔ∏è Exemple 2 : Cha√Æne d'effets compl√®te

### Objectif

Cr√©er une cha√Æne d'effets avec compresseur et delay pour un effet professionnel.

```javascript
class ProfessionalAudioChain {
  constructor() {
    this.effectsModule = new NativeAudioEffectsModule();
    this.compressorId = null;
    this.delayId = null;
    this.isInitialized = false;
  }

  async initialize() {
    try {
      // Initialisation du module
      await this.effectsModule.initialize();

      // Configuration du compresseur
      this.compressorId = await this.effectsModule.createEffect({
        type: 'compressor',
        parameters: {
          thresholdDb: -6.0, // Seuil plus sensible
          ratio: 6.0, // Compression plus agressive
          attackMs: 5.0, // Attack tr√®s rapide
          releaseMs: 150.0, // Release plus lente
          makeupDb: 3.0, // Makeup gain pour compenser
        },
        enabled: true,
      });

      // Configuration du delay
      this.delayId = await this.effectsModule.createEffect({
        type: 'delay',
        parameters: {
          delayMs: 300.0, // Delay rythmique
          feedback: 0.4, // Feedback mod√©r√©
          mix: 0.3, // Mix subtil
        },
        enabled: true,
      });

      if (this.compressorId === -1 || this.delayId === -1) {
        throw new Error('√âchec de la cr√©ation des effets');
      }

      this.isInitialized = true;
      console.log("Cha√Æne d'effets initialis√©e");
    } catch (error) {
      console.error("Erreur d'initialisation:", error);
      throw error;
    }
  }

  // Traitement audio st√©r√©o
  async processAudio(leftChannel, rightChannel) {
    if (!this.isInitialized) {
      throw new Error('Module non initialis√©');
    }

    try {
      const result = await this.effectsModule.processAudioStereo(
        leftChannel,
        rightChannel,
      );

      return {
        left: result.left,
        right: result.right,
      };
    } catch (error) {
      console.error('Erreur de traitement:', error);
      // Retour des buffers originaux en cas d'erreur
      return {
        left: leftChannel,
        right: rightChannel,
      };
    }
  }

  // Ajustement dynamique des param√®tres
  async adjustForLoudness() {
    if (!this.isInitialized) return;

    // R√©cup√©ration des m√©triques actuelles
    const compressorMetrics = await this.effectsModule.getCompressorMetrics(
      this.compressorId,
    );

    if (compressorMetrics) {
      // Ajustement adaptatif du seuil bas√© sur le niveau d'entr√©e
      const currentInputLevel = compressorMetrics.inputLevel;

      if (currentInputLevel > -6.0) {
        // Signal fort - compression plus agressive
        await this.effectsModule.updateEffect(this.compressorId, {
          thresholdDb: -3.0,
          ratio: 8.0,
        });
      } else if (currentInputLevel < -20.0) {
        // Signal faible - compression plus douce
        await this.effectsModule.updateEffect(this.compressorId, {
          thresholdDb: -12.0,
          ratio: 4.0,
        });
      }
    }
  }

  // Nettoyage
  async dispose() {
    const effects = [this.compressorId, this.delayId].filter(id => id !== null);

    for (const effectId of effects) {
      await this.effectsModule.destroyEffect(effectId);
    }

    await this.effectsModule.dispose();
    this.isInitialized = false;
  }
}

// Utilisation avanc√©e
const audioChain = new ProfessionalAudioChain();
await audioChain.initialize();

// Traitement audio st√©r√©o
const leftInput = [0.1, 0.3, 0.5, 0.2];
const rightInput = [0.1, 0.2, 0.4, 0.3];

const processed = await audioChain.processAudio(leftInput, rightInput);
console.log('Audio st√©r√©o trait√©:', processed);

// Ajustement adaptatif
await audioChain.adjustForLoudness();

// Nettoyage
await audioChain.dispose();
```

## üìä Exemple 3 : Monitoring temps r√©el

### Objectif

Surveiller les performances et m√©triques du syst√®me en temps r√©el.

```javascript
class AudioEffectsMonitor {
  constructor() {
    this.effectsModule = new NativeAudioEffectsModule();
    this.monitoring = false;
    this.effects = new Map();
  }

  async initialize() {
    try {
      await this.effectsModule.initialize();

      // Configuration des callbacks
      this.setupCallbacks();

      console.log("Moniteur d'effets initialis√©");
    } catch (error) {
      console.error("Erreur d'initialisation du moniteur:", error);
      throw error;
    }
  }

  setupCallbacks() {
    // Callback d'erreur
    this.effectsModule.setErrorCallback(error => {
      console.error("Erreur d'effet:", {
        code: error.code,
        message: error.message,
        effectId: error.effectId,
      });
    });

    // Callback de changement d'√©tat
    this.effectsModule.setStateChangeCallback(state => {
      console.log("Changement d'√©tat:", {
        ancien: state.oldState,
        nouveau: state.newState,
        timestamp: new Date(state.timestamp),
      });
    });

    // Callback de traitement
    this.effectsModule.setProcessingCallback(event => {
      if (event.type === 'processing_complete') {
        this.logMetrics(event.effectId, event.metrics);
      }
    });
  }

  logMetrics(effectId, metrics) {
    console.log(`M√©triques effet ${effectId}:`, {
      niveauEntree: `${metrics.inputLevel?.toFixed(2)} dB`,
      niveauSortie: `${metrics.outputLevel?.toFixed(2)} dB`,
      tempsTraitement: `${metrics.processingTime?.toFixed(2)} ms`,
      latence: metrics.latency ? `${metrics.latency.toFixed(2)} ms` : 'N/A',
    });
  }

  async startMonitoring(intervalMs = 1000) {
    this.monitoring = true;

    const monitoringLoop = async () => {
      if (!this.monitoring) return;

      try {
        // Statistiques g√©n√©rales
        const stats = await this.effectsModule.getStatistics();
        if (stats) {
          console.log('Statistiques syst√®me:', {
            tempsTraitement: `${stats.processingTime?.toFixed(2)} ms`,
            utilisationCPU: `${stats.cpuUsage?.toFixed(1)}%`,
            effetsActifs: stats.activeEffects,
            tailleBuffer: stats.bufferSize,
          });
        }

        // M√©triques par effet
        for (const [name, id] of this.effects) {
          const config = await this.effectsModule.getEffectConfig(id);
          const enabled = await this.effectsModule.isEffectEnabled(id);

          console.log(`Effet ${name} (${id}):`, {
            actif: enabled,
            type: config?.type,
            parametres: config?.parameters,
          });
        }

        // Planifier la prochaine it√©ration
        setTimeout(monitoringLoop, intervalMs);
      } catch (error) {
        console.error('Erreur de monitoring:', error);
        setTimeout(monitoringLoop, intervalMs);
      }
    };

    monitoringLoop();
  }

  stopMonitoring() {
    this.monitoring = false;
  }

  async createMonitoredEffect(name, config) {
    const effectId = await this.effectsModule.createEffect(config);
    if (effectId !== -1) {
      this.effects.set(name, effectId);
      console.log(`Effet surveill√© cr√©√©: ${name} (ID: ${effectId})`);
    }
    return effectId;
  }

  async dispose() {
    this.stopMonitoring();

    // Destruction de tous les effets
    for (const [name, id] of this.effects) {
      await this.effectsModule.destroyEffect(id);
      console.log(`Effet d√©truit: ${name}`);
    }

    this.effects.clear();
    await this.effectsModule.dispose();
  }
}

// Utilisation du moniteur
const monitor = new AudioEffectsMonitor();
await monitor.initialize();

// Cr√©ation d'effets surveill√©s
const compId = await monitor.createMonitoredEffect('compresseur', {
  type: 'compressor',
  parameters: {
    thresholdDb: -10.0,
    ratio: 4.0,
    attackMs: 10.0,
    releaseMs: 100.0,
  },
});

const delayId = await monitor.createMonitoredEffect('delay', {
  type: 'delay',
  parameters: {
    delayMs: 200.0,
    feedback: 0.3,
    mix: 0.4,
  },
});

// D√©marrage du monitoring
monitor.startMonitoring(2000); // Toutes les 2 secondes

// Simulation de traitement audio
setInterval(async () => {
  const testBuffer = Array.from(
    { length: 1024 },
    () => Math.random() * 0.5 - 0.25,
  );

  try {
    const processed = await monitor.effectsModule.processAudio(testBuffer, 1);
    console.log('Buffer trait√© avec succ√®s');
  } catch (error) {
    console.error('Erreur de traitement:', error);
  }
}, 5000);

// Nettoyage apr√®s 30 secondes
setTimeout(async () => {
  monitor.stopMonitoring();
  await monitor.dispose();
  console.log('Monitoring termin√©');
}, 30000);
```

## üéöÔ∏è Exemple 4 : Contr√¥leur MIDI

### Objectif

Contr√¥ler les effets audio via une interface MIDI pour un contr√¥le professionnel.

```javascript
class MIDIAudioController {
  constructor() {
    this.effectsModule = new NativeAudioEffectsModule();
    this.effects = new Map();
    this.midiController = null;
    this.isInitialized = false;
  }

  async initialize() {
    try {
      await this.effectsModule.initialize();

      // Cr√©ation des effets avec mapping MIDI
      await this.setupEffects();

      // Configuration MIDI
      await this.setupMIDI();

      this.isInitialized = true;
      console.log('Contr√¥leur MIDI initialis√©');
    } catch (error) {
      console.error("Erreur d'initialisation MIDI:", error);
      throw error;
    }
  }

  async setupEffects() {
    // Compresseur mappable
    const compId = await this.effectsModule.createEffect({
      type: 'compressor',
      parameters: {
        thresholdDb: -12.0,
        ratio: 4.0,
        attackMs: 15.0,
        releaseMs: 120.0,
        makeupDb: 0.0,
      },
    });

    this.effects.set('compressor', {
      id: compId,
      midiMappings: {
        threshold: { cc: 16, min: -60, max: 0 }, // CC 16
        ratio: { cc: 17, min: 1, max: 20 }, // CC 17
        attack: { cc: 18, min: 0.1, max: 100 }, // CC 18
        release: { cc: 19, min: 0.1, max: 1000 }, // CC 19
        makeup: { cc: 20, min: -20, max: 20 }, // CC 20
      },
    });

    // Delay mappable
    const delayId = await this.effectsModule.createEffect({
      type: 'delay',
      parameters: {
        delayMs: 250.0,
        feedback: 0.35,
        mix: 0.4,
      },
    });

    this.effects.set('delay', {
      id: delayId,
      midiMappings: {
        delayTime: { cc: 21, min: 1, max: 2000 }, // CC 21
        feedback: { cc: 22, min: 0, max: 0.99 }, // CC 22
        mix: { cc: 23, min: 0, max: 1 }, // CC 23
      },
    });
  }

  async setupMIDI() {
    try {
      if (navigator.requestMIDIAccess) {
        const midiAccess = await navigator.requestMIDIAccess();

        for (const input of midiAccess.inputs.values()) {
          input.onmidimessage = this.handleMIDIMessage.bind(this);
          console.log(`Port MIDI connect√©: ${input.name}`);
        }
      } else {
        console.warn('Web MIDI non support√©');
      }
    } catch (error) {
      console.error("Erreur d'acc√®s MIDI:", error);
    }
  }

  handleMIDIMessage(message) {
    const [status, controller, value] = message.data;

    // V√©rification si c'est un message Control Change (CC)
    if ((status & 0xf0) === 0xb0) {
      this.handleControlChange(controller, value);
    }
  }

  handleControlChange(controller, value) {
    // Conversion de la valeur MIDI (0-127) en valeur normalis√©e (0-1)
    const normalizedValue = value / 127.0;

    // Recherche de l'effet qui utilise ce contr√¥leur
    for (const [effectName, effect] of this.effects) {
      for (const [paramName, mapping] of Object.entries(effect.midiMappings)) {
        if (mapping.cc === controller) {
          this.updateEffectParameter(
            effect.id,
            paramName,
            normalizedValue,
            mapping,
          );
          return;
        }
      }
    }
  }

  async updateEffectParameter(effectId, paramName, normalizedValue, mapping) {
    try {
      // Conversion de la valeur normalis√©e vers la plage du param√®tre
      const paramValue =
        mapping.min + (mapping.max - mapping.min) * normalizedValue;

      const updateConfig = {};

      // Mapping des noms de param√®tres
      switch (paramName) {
        case 'threshold':
          updateConfig.thresholdDb = paramValue;
          break;
        case 'ratio':
          updateConfig.ratio = paramValue;
          break;
        case 'attack':
          updateConfig.attackMs = paramValue;
          break;
        case 'release':
          updateConfig.releaseMs = paramValue;
          break;
        case 'makeup':
          updateConfig.makeupDb = paramValue;
          break;
        case 'delayTime':
          updateConfig.delayMs = paramValue;
          break;
        case 'feedback':
          updateConfig.feedback = paramValue;
          break;
        case 'mix':
          updateConfig.mix = paramValue;
          break;
      }

      await this.effectsModule.updateEffect(effectId, updateConfig);

      console.log(
        `Param√®tre mis √† jour: ${paramName} = ${paramValue.toFixed(2)}`,
      );
    } catch (error) {
      console.error('Erreur de mise √† jour du param√®tre:', error);
    }
  }

  // M√©thodes utilitaires
  async getEffectParameters(effectName) {
    const effect = this.effects.get(effectName);
    if (effect) {
      return await this.effectsModule.getEffectConfig(effect.id);
    }
    return null;
  }

  async toggleEffect(effectName) {
    const effect = this.effects.get(effectName);
    if (effect) {
      const isEnabled = await this.effectsModule.isEffectEnabled(effect.id);
      await this.effectsModule.enableEffect(effect.id, !isEnabled);
      console.log(`${effectName} ${!isEnabled ? 'activ√©' : 'd√©sactiv√©'}`);
    }
  }

  async dispose() {
    for (const [name, effect] of this.effects) {
      await this.effectsModule.destroyEffect(effect.id);
    }

    this.effects.clear();
    await this.effectsModule.dispose();
    this.isInitialized = false;
  }
}

// Utilisation du contr√¥leur MIDI
const midiController = new MIDIAudioController();
await midiController.initialize();

// Simulation de messages MIDI (pour test)
function simulateMIDI(cc, value) {
  midiController.handleControlChange(cc, value);
}

// Test des contr√¥les MIDI
simulateMIDI(16, 64); // CC 16 (threshold) √† mi-course
simulateMIDI(17, 96); // CC 17 (ratio) √† 75%

// Nettoyage
await midiController.dispose();
```

## üéµ Exemple 5 : Int√©gration avec Web Audio

### Objectif

Int√©grer le syst√®me d'effets avec l'API Web Audio pour une cha√Æne audio compl√®te.

```javascript
class WebAudioEffectsChain {
  constructor() {
    this.effectsModule = new NativeAudioEffectsModule();
    this.audioContext = null;
    this.source = null;
    this.isInitialized = false;
  }

  async initialize() {
    try {
      // Initialisation du contexte Web Audio
      this.audioContext = new (window.AudioContext ||
        window.webkitAudioContext)();

      // Initialisation du module d'effets
      await this.effectsModule.initialize();

      // Cr√©ation des effets
      await this.setupAudioEffects();

      this.isInitialized = true;
      console.log('Cha√Æne Web Audio initialis√©e');
    } catch (error) {
      console.error("Erreur d'initialisation Web Audio:", error);
      throw error;
    }
  }

  async setupAudioEffects() {
    // Cr√©ation d'un processeur audio personnalis√©
    await this.audioContext.audioWorklet.addModule('audio-processor.js');

    // Cr√©ation du noeud de traitement
    this.audioProcessor = new AudioWorkletNode(
      this.audioContext,
      'audio-effects-processor',
    );

    // Configuration du processeur
    this.audioProcessor.port.postMessage({
      type: 'init',
      config: {
        sampleRate: this.audioContext.sampleRate,
        channels: 2,
      },
    });

    // Gestion des messages du processeur
    this.audioProcessor.port.onmessage = event => {
      if (event.data.type === 'processed') {
        // Donn√©es trait√©es re√ßues
        const processedData = event.data.result;
        // Traitement suppl√©mentaire si n√©cessaire
      }
    };
  }

  async processWithEffects(audioBuffer) {
    if (!this.isInitialized) {
      throw new Error('Syst√®me non initialis√©');
    }

    try {
      // Conversion du buffer Web Audio vers format natif
      const channelData = [];
      for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
        channelData.push(Array.from(audioBuffer.getChannelData(i)));
      }

      // Traitement avec les effets natifs
      const processedData = await this.effectsModule.processAudioStereo(
        channelData[0] || [],
        channelData[1] || [],
      );

      // Conversion vers buffer Web Audio de sortie
      const outputBuffer = this.audioContext.createBuffer(
        audioBuffer.numberOfChannels,
        audioBuffer.length,
        audioBuffer.sampleRate,
      );

      // Copie des donn√©es trait√©es
      if (processedData.left) {
        outputBuffer.copyToChannel(new Float32Array(processedData.left), 0);
      }
      if (processedData.right) {
        outputBuffer.copyToChannel(new Float32Array(processedData.right), 1);
      }

      return outputBuffer;
    } catch (error) {
      console.error('Erreur de traitement Web Audio:', error);
      return audioBuffer; // Retour buffer original en cas d'erreur
    }
  }

  async loadAudioFile(file) {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();

      reader.onload = async event => {
        try {
          const arrayBuffer = event.target.result;
          const audioBuffer = await this.audioContext.decodeAudioData(
            arrayBuffer,
          );
          resolve(audioBuffer);
        } catch (error) {
          reject(error);
        }
      };

      reader.onerror = () => reject(new Error('Erreur de lecture du fichier'));
      reader.readAsArrayBuffer(file);
    });
  }

  async playProcessedAudio(audioBuffer) {
    try {
      // Traitement du buffer
      const processedBuffer = await this.processWithEffects(audioBuffer);

      // Cr√©ation de la source
      this.source = this.audioContext.createBufferSource();
      this.source.buffer = processedBuffer;

      // Connexion √† la destination
      this.source.connect(this.audioContext.destination);

      // Lecture
      this.source.start();

      return true;
    } catch (error) {
      console.error('Erreur de lecture audio:', error);
      return false;
    }
  }

  stopPlayback() {
    if (this.source) {
      try {
        this.source.stop();
      } catch (error) {
        // Source d√©j√† arr√™t√©e
      }
      this.source = null;
    }
  }

  async dispose() {
    this.stopPlayback();

    if (this.audioProcessor) {
      this.audioProcessor.disconnect();
      this.audioProcessor = null;
    }

    await this.effectsModule.dispose();

    if (this.audioContext) {
      await this.audioContext.close();
      this.audioContext = null;
    }

    this.isInitialized = false;
  }
}

// Utilisation avec Web Audio
const audioChain = new WebAudioEffectsChain();
await audioChain.initialize();

// Gestionnaire de fichier audio
document.getElementById('audioFile').addEventListener('change', async event => {
  const file = event.target.files[0];
  if (file) {
    try {
      // Chargement du fichier
      const audioBuffer = await audioChain.loadAudioFile(file);

      // Lecture avec effets
      await audioChain.playProcessedAudio(audioBuffer);

      console.log('Audio jou√© avec effets');
    } catch (error) {
      console.error('Erreur de traitement audio:', error);
    }
  }
});

// Bouton d'arr√™t
document.getElementById('stopButton').addEventListener('click', () => {
  audioChain.stopPlayback();
});

// Nettoyage
window.addEventListener('beforeunload', async () => {
  await audioChain.dispose();
});
```

## üìã Exemple 6 : Tests et validation

### Objectif

Cr√©er des tests automatis√©s pour valider le fonctionnement du syst√®me d'effets.

```javascript
class AudioEffectsTester {
  constructor() {
    this.effectsModule = new NativeAudioEffectsModule();
    this.testResults = [];
  }

  async runAllTests() {
    console.log("üöÄ D√©marrage des tests d'effets audio...\n");

    try {
      await this.initializeModule();

      await this.testBasicInitialization();
      await this.testEffectCreation();
      await this.testParameterValidation();
      await this.testAudioProcessing();
      await this.testPerformanceMetrics();
      await this.testErrorHandling();

      this.displayResults();
    } catch (error) {
      console.error('‚ùå Erreur lors des tests:', error);
    } finally {
      await this.cleanup();
    }
  }

  async initializeModule() {
    console.log('üìã Test: Initialisation du module');
    const success = await this.effectsModule.initialize();
    this.assert(success, 'Module initialis√© avec succ√®s');
  }

  async testBasicInitialization() {
    console.log("\nüìã Test: V√©rification de l'√©tat initial");

    const isInitialized = await this.effectsModule.isInitialized();
    this.assert(isInitialized, 'Module signal√© comme initialis√©');

    const state = await this.effectsModule.getState();
    this.assert(state === 'initialized', `√âtat correct: ${state}`);
  }

  async testEffectCreation() {
    console.log("\nüìã Test: Cr√©ation d'effets");

    // Test cr√©ation compresseur
    const compId = await this.effectsModule.createEffect({
      type: 'compressor',
      parameters: {
        thresholdDb: -10.0,
        ratio: 4.0,
      },
    });

    this.assert(compId !== -1, `Compresseur cr√©√© avec ID: ${compId}`);

    // Test cr√©ation delay
    const delayId = await this.effectsModule.createEffect({
      type: 'delay',
      parameters: {
        delayMs: 100.0,
        feedback: 0.5,
      },
    });

    this.assert(delayId !== -1, `Delay cr√©√© avec ID: ${delayId}`);

    // V√©rification du nombre d'effets actifs
    const activeCount = await this.effectsModule.getActiveEffectsCount();
    this.assert(
      activeCount === 2,
      `Nombre d'effets actifs correct: ${activeCount}`,
    );

    // Nettoyage
    await this.effectsModule.destroyEffect(compId);
    await this.effectsModule.destroyEffect(delayId);
  }

  async testParameterValidation() {
    console.log('\nüìã Test: Validation des param√®tres');

    // Test param√®tres invalides
    try {
      await this.effectsModule.createEffect({
        type: 'compressor',
        parameters: {
          thresholdDb: 100.0, // Invalide
          ratio: -1.0, // Invalide
        },
      });
      this.assert(false, 'Devrait rejeter les param√®tres invalides');
    } catch (error) {
      this.assert(true, 'Param√®tres invalides correctement rejet√©s');
    }
  }

  async testAudioProcessing() {
    console.log('\nüìã Test: Traitement audio');

    const compId = await this.effectsModule.createEffect({
      type: 'compressor',
      parameters: {
        thresholdDb: -6.0,
        ratio: 4.0,
      },
    });

    // Buffer de test
    const testBuffer = [0.1, 0.5, 0.8, 0.3, 0.1];

    // Traitement
    const processedBuffer = await this.effectsModule.processAudio(
      testBuffer,
      1,
    );

    this.assert(Array.isArray(processedBuffer), 'Buffer trait√© retourn√©');

    this.assert(
      processedBuffer.length === testBuffer.length,
      'Longueur du buffer pr√©serv√©e',
    );

    this.assert(processedBuffer !== testBuffer, 'Nouveau buffer cr√©√©');

    await this.effectsModule.destroyEffect(compId);
  }

  async testPerformanceMetrics() {
    console.log('\nüìã Test: M√©triques de performance');

    const compId = await this.effectsModule.createEffect({
      type: 'compressor',
      parameters: {
        thresholdDb: -12.0,
        ratio: 6.0,
      },
    });

    // G√©n√©ration d'un buffer plus grand pour test
    const largeBuffer = Array.from(
      { length: 4096 },
      () => Math.random() * 0.8 - 0.4,
    );

    const startTime = performance.now();

    for (let i = 0; i < 10; i++) {
      await this.effectsModule.processAudio(largeBuffer, 1);
    }

    const endTime = performance.now();
    const avgProcessingTime = (endTime - startTime) / 10;

    console.log(
      `   Temps de traitement moyen: ${avgProcessingTime.toFixed(2)} ms`,
    );

    // R√©cup√©ration des m√©triques
    const stats = await this.effectsModule.getStatistics();

    if (stats) {
      this.assert(
        typeof stats.processingTime === 'number',
        'M√©triques de traitement disponibles',
      );

      console.log(`   M√©triques syst√®me:`, {
        processingTime: `${stats.processingTime?.toFixed(2)} ms`,
        cpuUsage: `${stats.cpuUsage?.toFixed(1)}%`,
        activeEffects: stats.activeEffects,
      });
    }

    await this.effectsModule.destroyEffect(compId);
  }

  async testErrorHandling() {
    console.log("\nüìã Test: Gestion d'erreurs");

    // Test destruction d'effet inexistant
    const result = await this.effectsModule.destroyEffect(999);
    this.assert(!result, "Destruction d'effet inexistant g√©r√©e");

    // Test acc√®s √† effet inexistant
    try {
      await this.effectsModule.getEffectConfig(999);
      this.assert(false, "Devrait rejeter l'acc√®s √† un effet inexistant");
    } catch (error) {
      this.assert(true, 'Acc√®s √† effet inexistant correctement rejet√©');
    }
  }

  assert(condition, message) {
    const result = {
      test: message,
      passed: condition,
      timestamp: new Date().toISOString(),
    };

    this.testResults.push(result);

    if (condition) {
      console.log(`   ‚úÖ ${message}`);
    } else {
      console.log(`   ‚ùå ${message}`);
    }
  }

  displayResults() {
    console.log('\nüìä R√âSULTATS DES TESTS');

    const passed = this.testResults.filter(r => r.passed).length;
    const total = this.testResults.length;

    console.log(
      `\nTests r√©ussis: ${passed}/${total} (${((passed / total) * 100).toFixed(
        1,
      )}%)`,
    );

    if (passed === total) {
      console.log('üéâ Tous les tests ont r√©ussi!');
    } else {
      console.log('\n‚ùå Tests √©chou√©s:');
      this.testResults
        .filter(r => !r.passed)
        .forEach(result => {
          console.log(`   - ${result.test}`);
        });
    }
  }

  async cleanup() {
    console.log('\nüßπ Nettoyage...');
    await this.effectsModule.dispose();
  }
}

// Ex√©cution des tests
const tester = new AudioEffectsTester();
await tester.runAllTests();
```

## üí° Meilleures pratiques

### Gestion des erreurs

```javascript
// Toujours envelopper les appels dans des try-catch
async function safeAudioProcessing(audioBuffer) {
  try {
    const processed = await effectsModule.processAudio(audioBuffer, 1);
    return processed;
  } catch (error) {
    console.error('Erreur de traitement audio:', error);

    // Fallback: retourner le buffer original
    return audioBuffer;
  }
}
```

### Optimisation des performances

```javascript
// Traiter les buffers par blocs pour √©viter la surcharge
const BUFFER_SIZE = 1024;
const OVERLAP = 128;

async function processLargeBuffer(audioBuffer) {
  const results = [];

  for (let i = 0; i < audioBuffer.length; i += BUFFER_SIZE - OVERLAP) {
    const chunk = audioBuffer.slice(i, i + BUFFER_SIZE);
    const processedChunk = await effectsModule.processAudio(chunk, 1);
    results.push(processedChunk);
  }

  // Recombiner les chunks trait√©s
  return results.flat();
}
```

### Gestion des ressources

```javascript
// Utiliser un gestionnaire de contexte pour garantir le nettoyage
class EffectsContext {
  constructor() {
    this.effectsModule = new NativeAudioEffectsModule();
    this.effects = [];
  }

  async __aenter__() {
    await this.effectsModule.initialize();
    return this;
  }

  async __aexit__(type, value, traceback) {
    // Nettoyage automatique
    for (const effectId of this.effects) {
      await this.effectsModule.destroyEffect(effectId);
    }
    await this.effectsModule.dispose();
  }

  async createEffect(config) {
    const effectId = await this.effectsModule.createEffect(config);
    this.effects.push(effectId);
    return effectId;
  }
}

// Utilisation avec async context manager (Python-like)
const async with = async (contextManager, callback) => {
  const context = await contextManager.__aenter__();
  try {
    return await callback(context);
  } finally {
    await contextManager.__aexit__(null, null, null);
  }
};

// Exemple d'utilisation
const result = await with(new EffectsContext(), async (ctx) => {
  const compId = await ctx.createEffect({ type: 'compressor' });
  return await ctx.effectsModule.processAudio(buffer, 1);
});
```

---

**Note** : Ces exemples peuvent √™tre adapt√©s selon vos besoins sp√©cifiques. Ils illustrent les patterns de conception recommand√©s et les meilleures pratiques pour l'utilisation du syst√®me d'effets audio.
